{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/pytube/pytube\n",
      "  Cloning https://github.com/pytube/pytube to /private/var/folders/wm/vt5jkwy10xs_7zv7nc5w67wr0000gn/T/pip-req-build-lu6r484l\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/pytube/pytube /private/var/folders/wm/vt5jkwy10xs_7zv7nc5w67wr0000gn/T/pip-req-build-lu6r484l\n",
      "  Resolved https://github.com/pytube/pytube to commit a32fff39058a6f7e5e59ecd06a7467b71197ce35\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/pytube/pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(dotenv_path=\"../env_file/.env\")\n",
    "\n",
    "# Set API key for OpenAI client\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "\n",
    "def download_audio(video_url, output_path=\"audio.mp3\"):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'outtmpl': output_path,\n",
    "        'ffmpeg_location': '/opt/homebrew/bin',  # This line tells yt-dlp where to find ffmpeg\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "            'preferredquality': '192',\n",
    "        }],\n",
    "        'quiet': True\n",
    "    }\n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([video_url])\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading audio: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio_path):\n",
    "    try:\n",
    "        with open(audio_path, \"rb\") as audio_file:\n",
    "            transcript = openai.audio.transcriptions.create(\n",
    "                model=\"whisper-1\",\n",
    "                file=audio_file,\n",
    "                response_format=\"text\"\n",
    "            )\n",
    "        return transcript\n",
    "    except Exception as e:\n",
    "        print(f\"Error transcribing audio: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(transcript_text, mode=\"basic\"):\n",
    "    if mode == \"bullets\":\n",
    "        return f\"Summarize the following transcript into concise bullet points with timestamps when possible:\\n\\n{transcript_text}\"\n",
    "    elif mode == \"quotes\":\n",
    "        return f\"Extract the most insightful or notable quotes with timestamps from the following transcript:\\n\\n{transcript_text}\"\n",
    "    elif mode == \"insights\":\n",
    "        return f\"Summarize the following transcript into key insights, trends, or warnings with timestamp references:\\n\\n{transcript_text}\"\n",
    "    else:\n",
    "        return f\"Summarize the following transcript:\\n\\n{transcript_text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_transcript(transcript_text, mode=\"basic\"):\n",
    "    try:\n",
    "        prompt = build_prompt(transcript_text, mode)\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.7,\n",
    "            max_tokens=800\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error summarizing transcript: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter YouTube URL:  https://www.youtube.com/watch?v=59t62NHJFH4\n",
      "Choose summary style (basic, bullets, quotes, insights):  bullets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             \n",
      "--- Transcript fetched ---\n",
      "\n",
      "\n",
      "--- Summary ---\n",
      "\n",
      "- AI is rapidly progressing with significant developments such as generative AI and reasoning models. \n",
      "- In 2025, a Chinese startup, DeepSeek, introduced an AI model that disrupted the industry, causing a trillion-dollar valuation drop in major AI players like OpenAI and Microsoft.\n",
      "- AI is impacting many areas including analytics, machine learning, pattern recognition, content creation, and problem-solving.\n",
      "- The cutting edge of AI is moving towards agentic AI, where AI acts as agents performing tasks such as booking flights or restocking fridges.\n",
      "- With AI being able to think, reason, and make decisions, there is a potential for misuse, misinformation, and influence.\n",
      "- Interaction with AI is mostly through prompting, but there are limitations such as the hallucination problem where AI provides incorrect information when it doesn't know an answer.\n",
      "- AI systems are programmed with personalities designed to be helpful and optimistic, which may lead to issues in high-criticality applications or an overoptimistic view of AI's impact.\n",
      "- Effective prompting of AI requires providing lots of context and specificity, especially for reasoning models.\n",
      "- Individuals need to actively engage with AI technology, experiment with new models, be vigilant about potential downsides, and be quick to embrace the upsides.\n",
      "- Michael Watkins, a professor of leadership and organizational change at the IMD Business School, emphasizes the need to adapt and stay ahead of this rapidly changing technology.\n"
     ]
    }
   ],
   "source": [
    "url = input(\"Enter YouTube URL: \")\n",
    "mode = input(\"Choose summary style (basic, bullets, quotes, insights): \")\n",
    "audio_file = download_audio(url)\n",
    "\n",
    "if audio_file:\n",
    "    transcript_text = transcribe_audio(audio_file)\n",
    "    if transcript_text:\n",
    "        print(\"\\n--- Transcript fetched ---\\n\")\n",
    "        summary = summarize_transcript(transcript_text, mode)\n",
    "        if summary:\n",
    "            print(\"\\n--- Summary ---\\n\")\n",
    "            print(summary)\n",
    "        else:\n",
    "            print(\"Summary generation failed.\")\n",
    "    else:\n",
    "        print(\"Transcription failed.\")\n",
    "else:\n",
    "    print(\"Audio download failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (YouTube Summarizer)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
