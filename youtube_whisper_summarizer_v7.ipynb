{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b3a6f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yt-dlp in ./venv/lib/python3.12/site-packages (2025.5.22)\n",
      "Requirement already satisfied: openai in ./venv/lib/python3.12/site-packages (1.83.0)\n",
      "Requirement already satisfied: python-dotenv in ./venv/lib/python3.12/site-packages (1.1.0)\n",
      "Requirement already satisfied: ipykernel in ./venv/lib/python3.12/site-packages (6.29.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv/lib/python3.12/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./venv/lib/python3.12/site-packages (from openai) (2.11.5)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./venv/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./venv/lib/python3.12/site-packages (from openai) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: appnope in ./venv/lib/python3.12/site-packages (from ipykernel) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./venv/lib/python3.12/site-packages (from ipykernel) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./venv/lib/python3.12/site-packages (from ipykernel) (1.8.14)\n",
      "Requirement already satisfied: ipython>=7.23.1 in ./venv/lib/python3.12/site-packages (from ipykernel) (9.3.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in ./venv/lib/python3.12/site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./venv/lib/python3.12/site-packages (from ipykernel) (5.8.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./venv/lib/python3.12/site-packages (from ipykernel) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in ./venv/lib/python3.12/site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.12/site-packages (from ipykernel) (24.2)\n",
      "Requirement already satisfied: psutil in ./venv/lib/python3.12/site-packages (from ipykernel) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in ./venv/lib/python3.12/site-packages (from ipykernel) (26.4.0)\n",
      "Requirement already satisfied: tornado>=6.1 in ./venv/lib/python3.12/site-packages (from ipykernel) (6.5.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in ./venv/lib/python3.12/site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: decorator in ./venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in ./venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (2.19.1)\n",
      "Requirement already satisfied: stack_data in ./venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in ./venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./venv/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.12/site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./venv/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.3.8)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install yt-dlp openai python-dotenv ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b79e10d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import subprocess\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import uuid\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(dotenv_path=\"../env_file/.env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09e80488",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_audio(video_url):\n",
    "    try:\n",
    "        unique_id = str(uuid.uuid4())\n",
    "        output_filename = f\"downloaded_audio_{unique_id}.mp3\"\n",
    "        command = [\n",
    "            'yt-dlp',\n",
    "            '-f', 'bestaudio',\n",
    "            '--extract-audio',\n",
    "            '--audio-format', 'mp3',\n",
    "            '--ffmpeg-location', '/opt/homebrew/bin/ffmpeg',\n",
    "            '--output', output_filename.replace(\".mp3\", \".%(ext)s\"),\n",
    "            video_url\n",
    "        ]\n",
    "        subprocess.run(command, check=True)\n",
    "        return output_filename\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading audio: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a12a13e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio_path):\n",
    "    try:\n",
    "        client = OpenAI()\n",
    "        with open(audio_path, \"rb\") as audio_file:\n",
    "            transcript = client.audio.transcriptions.create(\n",
    "                model=\"whisper-1\",\n",
    "                file=audio_file,\n",
    "                response_format=\"verbose_json\"\n",
    "            )\n",
    "        text = transcript.text\n",
    "        segments = transcript.segments\n",
    "        return text, segments\n",
    "    except Exception as e:\n",
    "        print(f\"Error transcribing audio: {e}\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bffd5b6-143d-4a4a-820d-0318b88e92cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_segments_with_timestamps(segments):\n",
    "    formatted = []\n",
    "    for seg in segments:\n",
    "        start = int(seg.start)\n",
    "        minutes = start // 60\n",
    "        seconds = start % 60\n",
    "        timestamp = f\"{minutes}:{seconds:02d}\"\n",
    "        formatted.append(f\"[{timestamp}] {seg.text}\")\n",
    "    return \"\\n\".join(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a77ae406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(transcript, segments, mode=\"basic\"):\n",
    "    prompts = {\n",
    "        \"basic\": f\"Summarize the following transcript:\\n\\n{transcript}\",\n",
    "        \"bullets\": f\"Summarize the following transcript into concise bullet points:\\n\\n{transcript}\",\n",
    "        \"quotes\": f\"Extract 5-10 of the most compelling or insightful quotes from this transcript. Include timestamps:\\n\\n{format_segments_with_timestamps(segments)}\",\n",
    "        \"insights\": f\"Summarize the following transcript by extracting the key insights and implications. Be concise but thoughtful:\\n\\n{transcript}\"\n",
    "    }\n",
    "\n",
    "    prompt = prompts.get(mode, prompts[\"basic\"])\n",
    "\n",
    "    try:\n",
    "        client = OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.7,\n",
    "            max_tokens=700\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating summary: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf032bc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter YouTube URL:  https://www.youtube.com/watch?v=2Zbg5iuDxOg\n",
      "Choose summary style (basic, bullets, quotes, insights):  quotes\n",
      "Would you like to see the full transcript first? (yes/no):  yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=2Zbg5iuDxOg\n",
      "[youtube] 2Zbg5iuDxOg: Downloading webpage\n",
      "[youtube] 2Zbg5iuDxOg: Downloading tv client config\n",
      "[youtube] 2Zbg5iuDxOg: Downloading tv player API JSON\n",
      "[youtube] 2Zbg5iuDxOg: Downloading ios player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] 2Zbg5iuDxOg: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n",
      "WARNING: [youtube] 2Zbg5iuDxOg: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] 2Zbg5iuDxOg: Downloading m3u8 information\n",
      "[info] 2Zbg5iuDxOg: Downloading 1 format(s): 234\n",
      "[hlsnative] Downloading m3u8 manifest\n",
      "[hlsnative] Total fragments: 104\n",
      "[download] Destination: downloaded_audio_f3982cbb-8a0e-4d8c-b32f-c5d86daa8205.mp4\n",
      "[download] 100% of    8.19MiB in 00:00:16 at 520.53KiB/s                 \n",
      "[ExtractAudio] Destination: downloaded_audio_f3982cbb-8a0e-4d8c-b32f-c5d86daa8205.mp3\n",
      "Deleting original file downloaded_audio_f3982cbb-8a0e-4d8c-b32f-c5d86daa8205.mp4 (pass -k to keep)\n",
      "\n",
      "--- Transcript fetched ---\n",
      "\n",
      "AI has opened a new continent, and humanity is setting foot on its shores. Since humans have walked the planet, we've always been the most impressive, intelligent beings. But today, AI is forcing us to ask the question, what does it mean to be human? To live a flourishing human life? Major moments in science and technology shed new light on long-standing philosophical questions. Copernicus dislodged us from our central position in the cosmos. Charles Darwin and his theory of evolution situated us among the animals. And Albert Einstein and his theory of relativity revealed the limits of our senses and our bare intuition. Now in the age of Turing, technology pushes us to philosophy once again. Philosophy offers not godlike wisdom, but a powerful set of tools of inquiry to move past dogma, past tribalism, and navigate the journey ahead. And the stakes have never been higher. For the past 200,000 years, humans have created technology as tools, as means to our ends. But today, we're creating technology in AI that has the potential to shape both the means and the ends of human endeavor. The printing press never determined what was printed, but today, 20% of human discretionary time is mediated by algorithms that do determine what information is consumed and even how we decide what's good for us. The upside potential to technology is staggering. Consider cancer. Today, a doctor can feed medical images to AI, and AI can detect tumors. Tomorrow, AI may even be able to expand our fundamental knowledge of cancer, acting like a human scientist would, and maybe even much better. But what happens when the technology evolves from a tool to an overseer? What happens when it starts to substitute for our most essential human capacities? One risk is that, for the sake of incremental convenience, we offload big aspects of our existence to a kind of super-intelligent schoolmaster that tells us what to think and what to do. Another is that we create a governance structure to control the technology that ends up doing the same. How do we realize the benefits of AI while protecting the active use of freedom, that precious gift of modernity that allows us to realize what makes us essentially human? Today there are two primary philosophies in the AI field. The first is existential pessimism, or the view that AI poses a dire risk to humanity. This school wants to hit the pause button. But imagine hitting pause before Darwin, before Einstein, or at any point in human history. The losses to humanity would have been incalculably large. In an open society, hitting pause is as impossible as it is unwise. But what is possible, and even likely, is that the quest to optimize the world for safety ends up creating a governance structure that suffocates innovation, harms freedom, and amplifies bad actors. The opposing school, accelerationism, embraces the power of markets and the role of optimism. But some of the leaders of this movement neglect to put the human at the center. For them, technology shifts from being a means to being the sole end of human life. Some of these individuals want to accelerate towards the moment when humans pass the baton to AI as the next link in the evolutionary chain. Now I understand the appeal of saving humanity from extinction. I understand the appeal of building God. But both of these philosophies are misguided. What we need is a genuinely positive, humanistic vision for the future of AI. Here are three steps to get there. Step one, the North Star. Just like the North Star gives you direction, any new AI philosophy needs to be oriented around the goal of human flourishing. Human flourishing here means discovering and developing your unique gifts and applying them to become the person that you aspire to be. We need AI and its governance to serve humans rather than humans serving it. Step two, the compass. A compass is a tool to help us navigate, to help us make decisions along the way. There are three points on the AI compass. One is human autonomy, two is reason, and three is decentralization. Human autonomy is the state of being free in our mind and interactions. Aristotle taught that autonomy was essential for the full realization of our highest capacities and to live by our well-considered choices. Without autonomy, we shift from free agents to passive agents who are increasingly dependent on algorithms to tell us what to do and how to think. Reason is the superpower we use when our mind considers alternatives in pursuit of the truth. John Stuart Mill fought for the widened access to diverse and competing opinions because he thought it was essential for the pursuit of truth and the cultivation of reason. If AI causes reason to atrophy, humans will slip into dogmatism, intolerance, and persecution. And fields of endeavor that depend on reason, like science, will stall. Decentralization is like having millions of mini-captains instead of one big boss at the top. When Alexis de Tocqueville stepped on the shores of America, he saw a nation characterized by spontaneous association of individuals who, from the bottom up, were rallying together around common interests. If we lose decentralization, then individuals will succumb to the strong centralizing forces in society, whether that is majority opinion on social media, state control, or a super-intelligent master planner. Step three, navigating the new world. How do we use the North Star and the compass to start navigating this new world? 250 years ago, America's founders came together to build this philosophy-to-law pipeline. Today, we need to build a philosophy-to-code pipeline. We need to bring practitioners together with philosophers to translate these vital concepts of human autonomy, reason, and decentralization into the planetary-scale systems shaping our future. To do this, we're helping create the first AI lab in the world dedicated to translating the principles of human flourishing into open-source software. It's called the Human-Centered AI Lab at Oxford University. Top technology talent, more than ever before, needs to build systems that are animated by this North Star of human flourishing. But this requires cultivating a new kind of technologist, a technologist that has world-class AI talent on the one hand, and also deep capacity for philosophical thought on the other. Then we need to support those individuals who can build provocative new prototypes to show us how AI and human flourishing come together. We're at a pivotal point in human history, taking first steps into the unknown. If we follow the North Star, if we use the compass, we can settle on this new continent, we can build a vibrant society from the ground up, and we can ensure that technology amplifies human potential and doesn't diminish it. From Copernicus to Tern, it's time to once again find our place in the cosmos.\n",
      "\n",
      "--- Summary ---\n",
      "\n",
      "1. \"AI has opened a new continent, and humanity is setting foot on its shores.\" [0:00]\n",
      "2. \"But today, AI is forcing us to ask the question, what does it mean to be human? To live a flourishing human life?\" [0:11-0:16]\n",
      "3. \"Now in the age of Turing, technology pushes us to philosophy once again.\" [0:42]\n",
      "4. \"For the past 200,000 years, humans have created technology as tools, as means to our ends. But today, we're creating technology in AI that has the potential to shape both the means and the ends of human endeavor.\" [1:09-1:21]\n",
      "5. \"How do we realize the benefits of AI while protecting the active use of freedom, that precious gift of modernity that allows us to realize what makes us essentially human?\" [2:35-2:41]\n",
      "6. \"What we need is a genuinely positive, humanistic vision for the future of AI.\" [4:22]\n",
      "7. \"We need AI and its governance to serve humans rather than humans serving it.\" [4:52-4:59]\n",
      "8. \"Today, we need to build a philosophy-to-code pipeline. We need to bring practitioners together with philosophers to translate these vital concepts of human autonomy, reason, and decentralization into the planetary-scale systems shaping our future.\" [7:06-7:16]\n",
      "9. \"If we follow the North Star, if we use the compass, we can settle on this new continent, we can build a vibrant society from the ground up, and we can ensure that technology amplifies human potential and doesn't diminish it.\" [8:14-8:27]\n",
      "10. \"From Copernicus to Turing, it's time to once again find our place in the cosmos.\" [8:31]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "video_url = input(\"Enter YouTube URL: \").strip()\n",
    "mode = input(\"Choose summary style (basic, bullets, quotes, insights): \").strip().lower()\n",
    "show_transcript = input(\"Would you like to see the full transcript first? (yes/no): \").strip().lower()\n",
    "\n",
    "audio_file = download_audio(video_url)\n",
    "\n",
    "if audio_file:\n",
    "    transcript_text, segments = transcribe_audio(audio_file)\n",
    "    if transcript_text:\n",
    "        if show_transcript == \"yes\":\n",
    "            print(\"\\n--- Transcript fetched ---\\n\")\n",
    "            print(transcript_text)\n",
    "\n",
    "        print(\"\\n--- Summary ---\\n\")\n",
    "        print(summarize_text(transcript_text, segments, mode))\n",
    "    else:\n",
    "        print(\"Transcription failed.\")\n",
    "else:\n",
    "    print(\"Audio download failed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccaba15-a4d0-437f-8250-c2ec48525c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (YouTube Summarizer)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
